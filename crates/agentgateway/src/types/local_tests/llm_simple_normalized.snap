---
source: crates/agentgateway/src/types/local_tests.rs
description: "Config normalization test for llm_simple: YAML -> LocalConfig -> NormalizedLocalConfig -> YAML"
---
binds:
- key: bind/4000
  address: '[::]:4000'
  protocol: http
  tunnelProtocol: direct
  listeners:
    llm:
      key: llm
      gatewayName: name
      gatewayNamespace: ns
      listenerName: llm
      hostname: '*'
      protocol: HTTP
      routes:
        llm:model:claude-3-haiku:0:
          key: llm:model:claude-3-haiku:0
          name: model:claude-3-haiku
          namespace: internal
          matches:
          - headers:
            - name: x-org
              value:
                exact: engineering
            - name: x-gateway-model-name
              value:
                exact: claude-3-haiku
            path:
              pathPrefix: /
          backends:
          - weight: 1
            backend: /llm:claude-3-haiku
          inlinePolicies:
          - ai:
              routes:
                /v1/chat/completions: completions
                :streamRawPredict: messages
                /v1/embeddings: embeddings
                /v1/responses: responses
                /v1/messages: messages
                :rawPredict: messages
                '*': passthrough
        llm:model:gpt-7-max:2:
          key: llm:model:gpt-7-max:2
          name: model:gpt-7-max
          namespace: internal
          matches:
          - headers:
            - name: x-gateway-model-name
              value:
                exact: gpt-7-max
            path:
              pathPrefix: /
          backends:
          - weight: 1
            backend: /llm:gpt-7-max
          inlinePolicies:
          - ai:
              routes:
                /v1/chat/completions: completions
                :streamRawPredict: messages
                /v1/embeddings: embeddings
                /v1/responses: responses
                /v1/messages: messages
                :rawPredict: messages
                '*': passthrough
        llm:model:gpt-3.5-turbo:3:
          key: llm:model:gpt-3.5-turbo:3
          name: model:gpt-3.5-turbo
          namespace: internal
          matches:
          - headers:
            - name: x-gateway-model-name
              value:
                exact: gpt-3.5-turbo
            path:
              pathPrefix: /
          backends:
          - weight: 1
            backend: /llm:gpt-3.5-turbo
          inlinePolicies:
          - ai:
              routes:
                /v1/chat/completions: completions
                :streamRawPredict: messages
                /v1/embeddings: embeddings
                /v1/responses: responses
                /v1/messages: messages
                :rawPredict: messages
                '*': passthrough
        llm:model:gemini-0.5-pro:1:
          key: llm:model:gemini-0.5-pro:1
          name: model:gemini-0.5-pro
          namespace: internal
          matches:
          - headers:
            - name: x-gateway-model-name
              value:
                exact: gemini-0.5-pro
            path:
              pathPrefix: /
          backends:
          - weight: 1
            backend: /llm:gemini-0.5-pro
          inlinePolicies:
          - ai:
              routes:
                /v1/chat/completions: completions
                :streamRawPredict: messages
                /v1/embeddings: embeddings
                /v1/responses: responses
                /v1/messages: messages
                :rawPredict: messages
                '*': passthrough
        llm:admin:model-list:
          key: llm:admin:model-list
          name: admin:model-list
          namespace: internal
          matches:
          - path:
              pathPrefix: /v1/models
          - path:
              pathPrefix: /models
          inlinePolicies:
          - directResponse:
              body: eyJkYXRhIjpbeyJpZCI6ImNsYXVkZS0zLWhhaWt1Iiwib2JqZWN0IjoibW9kZWwiLCJjcmVhdGVkIjoxNzcxMzcwNTczLCJvd25lZF9ieSI6Im9wZW5haSJ9LHsiaWQiOiJnZW1pbmktMC41LXBybyIsIm9iamVjdCI6Im1vZGVsIiwiY3JlYXRlZCI6MTc3MTM3MDU3Mywib3duZWRfYnkiOiJvcGVuYWkifSx7ImlkIjoiZ3B0LTctbWF4Iiwib2JqZWN0IjoibW9kZWwiLCJjcmVhdGVkIjoxNzcxMzcwNTczLCJvd25lZF9ieSI6Im9wZW5haSJ9LHsiaWQiOiJncHQtMy41LXR1cmJvIiwib2JqZWN0IjoibW9kZWwiLCJjcmVhdGVkIjoxNzcxMzcwNTczLCJvd25lZF9ieSI6Im9wZW5haSJ9XSwib2JqZWN0IjoibGlzdCJ9
              status: 200
      tcpRoutes: {}
policies:
- key: listener/0
  name: null
  target:
    gateway:
      gatewayName: name
      gatewayNamespace: ns
      listenerName: llm
  policy:
    traffic:
      phase: gateway
      jwtAuth:
        mode: optional
        providers:
        - issuer: agentgateway.dev
          keys: []
- key: listener/1
  name: null
  target:
    gateway:
      gatewayName: name
      gatewayNamespace: ns
      listenerName: llm
  policy:
    traffic:
      phase: route
      authorization:
        rules:
          allow:
          - jwt.email.endsWith("@example.com")
          deny: []
- key: llm:transformation
  name:
    kind: Local
    name: llm:transformation
    namespace: internal
  target:
    gateway:
      gatewayName: name
      gatewayNamespace: ns
      listenerName: llm
  policy:
    traffic:
      phase: gateway
      transformation:
        request:
          add: []
          set:
          - - x-gateway-model-name
            - |2

              request.path.endsWith(":streamRawPredict") || request.path.endsWith(":rawPredict") ?
              request.path.regexReplace("^.*/publishers/anthropic/models/(.+?):.*", "${1}") :
              json(request.body).model
          - - anthropic-beta
            - request.headers['anthropic-beta'].split(',').filter(v, v.trim() in [])
          remove: []
          body: null
        response:
          add: []
          set: []
          remove: []
          body: null
- key: frontend/accessLog
  name: null
  target:
    gateway:
      gatewayName: name
      gatewayNamespace: ns
      listenerName: null
  policy:
    frontend:
      accessLog:
        add:
          user: request.headers["user-agent"]
backends:
- backend:
    ai:
      name: llm:claude-3-haiku
      namespace: ''
      target:
        providers:
        - active:
            claude-3-haiku:
              endpoint:
                name: claude-3-haiku
                provider:
                  anthropic:
                    model: claude-3-5-haiku-20241022
                hostOverride: null
                pathOverride: null
                tokenize: false
                inlinePolicies:
                - backendAuth:
                    key: <redacted>
              info:
                health: 1.0
                request_latency: 0.0
                pending_requests: 0
                total_requests: 0
                evicted_until: null
          rejected: {}
  inlinePolicies:
  - requestHeaderModifier:
      remove:
      - x-gateway-model-name
  - ai: {}
- backend:
    ai:
      name: llm:gemini-0.5-pro
      namespace: ''
      target:
        providers:
        - active:
            gemini-0.5-pro:
              endpoint:
                name: gemini-0.5-pro
                provider:
                  vertex:
                    model: claude-3-5-haiku-20241022
                    region: global
                    projectId: my-vertex-project
                hostOverride: null
                pathOverride: null
                tokenize: false
                inlinePolicies:
                - backendAuth:
                    key: <redacted>
              info:
                health: 1.0
                request_latency: 0.0
                pending_requests: 0
                total_requests: 0
                evicted_until: null
          rejected: {}
  inlinePolicies:
  - requestHeaderModifier:
      remove:
      - x-gateway-model-name
  - ai: {}
- backend:
    ai:
      name: llm:gpt-7-max
      namespace: ''
      target:
        providers:
        - active:
            gpt-7-max:
              endpoint:
                name: gpt-7-max
                provider:
                  azureOpenAI:
                    model: gpt-3.5-turbo
                    host: my-azure-openai-endpoint.openai.azure.com
                    apiVersion: v1
                hostOverride: null
                pathOverride: null
                tokenize: false
              info:
                health: 1.0
                request_latency: 0.0
                pending_requests: 0
                total_requests: 0
                evicted_until: null
          rejected: {}
  inlinePolicies:
  - requestHeaderModifier:
      remove:
      - x-gateway-model-name
  - ai: {}
- backend:
    ai:
      name: llm:gpt-3.5-turbo
      namespace: ''
      target:
        providers:
        - active:
            gpt-3.5-turbo:
              endpoint:
                name: gpt-3.5-turbo
                provider:
                  openAI: {}
                hostOverride: null
                pathOverride: null
                tokenize: false
              info:
                health: 1.0
                request_latency: 0.0
                pending_requests: 0
                total_requests: 0
                evicted_until: null
          rejected: {}
  inlinePolicies:
  - requestHeaderModifier:
      remove:
      - x-gateway-model-name
  - ai: {}
workloads: []
services: []
